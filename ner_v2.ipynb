{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e14a6be",
   "metadata": {},
   "source": [
    "# Task 2: Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38fecf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import json, requests\n",
    "import re\n",
    "import os\n",
    "wandb_api_key = \"1a489be8947a5bbf94fcc41855e40beaab35312e\" # replace with your own wandb_api_key\n",
    "os.environ['WANDB_API_KEY'] = wandb_api_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4f6e86",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd0bc44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Patients</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>experienced</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>cough</td>\n",
       "      <td>B-SYMPTOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>after</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>administration</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>75mg</td>\n",
       "      <td>B-DOSAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>DrugZ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id            word        tag\n",
       "0            1        Patients          O\n",
       "1            1     experienced          O\n",
       "2            1           cough  B-SYMPTOM\n",
       "3            1           after          O\n",
       "4            1  administration          O\n",
       "5            1              of          O\n",
       "6            1            75mg   B-DOSAGE\n",
       "7            1              of          O\n",
       "8            1           DrugZ          O"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_drive = \"ner_data.csv\"\n",
    "ner_df = pd.read_csv(file_path_drive)\n",
    "ner_df[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac75b668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique entity counts:\n",
      "entity_type\n",
      "DOSAGE     8\n",
      "SYMPTOM    8\n",
      "Name: word, dtype: int64\n",
      "\n",
      "Detailed breakdown:\n",
      "\n",
      "DOSAGE (Total unique: 8):\n",
      "['75mg' '500mg' '200mg' '100mg' '10mg' '50mg' '250mg' '5mg']\n",
      "\n",
      "DRUG (Total unique: 0):\n",
      "[]\n",
      "\n",
      "SYMPTOM (Total unique: 8):\n",
      "['cough' 'fever' 'rash' 'headache' 'dizziness' 'vomiting' 'fatigue'\n",
      " 'nausea']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michelle\\AppData\\Local\\Temp\\ipykernel_167792\\3215379747.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df['entity_type'] = entity_df['tag'].str.split('-').str[1]\n"
     ]
    }
   ],
   "source": [
    "# Count unique entities\n",
    "def count_unique_entities(df):\n",
    "    # Filter only entity rows (excluding 'O' tags)\n",
    "    entity_df = df[df['tag'] != 'O']\n",
    "\n",
    "    # Extract entity type from tag (B-DRUG -> DRUG)\n",
    "    entity_df['entity_type'] = entity_df['tag'].str.split('-').str[1]\n",
    "\n",
    "    # Group by entity type and count unique words\n",
    "    unique_counts = entity_df.groupby('entity_type')['word'].nunique()\n",
    "\n",
    "    return unique_counts\n",
    "\n",
    "# Get counts\n",
    "entity_counts = count_unique_entities(ner_df)\n",
    "print(\"Unique entity counts:\")\n",
    "print(entity_counts)\n",
    "\n",
    "# Alternative visualization\n",
    "print(\"\\nDetailed breakdown:\")\n",
    "for entity_type in ['DOSAGE', 'DRUG', 'SYMPTOM']:\n",
    "    unique_words = ner_df[ner_df['tag'] == f'B-{entity_type}']['word'].unique()\n",
    "    print(f\"\\n{entity_type} (Total unique: {len(unique_words)}):\")\n",
    "    print(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7e46d0",
   "metadata": {},
   "source": [
    "Although there are 1000 sentences, there is very little variability in the data. I plan to combine the sentences, remove duplicates, revert back to the IOB form, then generate more data in a way that I believe this synthetic dataset was made. I'm going to keep 1-word entities since the original dataset also only had 1-word entities (no I-SYMPTOM or I-DOSAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "083619b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of sentences: 1000\n",
      "Number of unique sentences: 825\n",
      "\n",
      "Sample of cleaned data:\n",
      "    sentence_id            word        tag\n",
      "0             1        Patients          O\n",
      "1             1     experienced          O\n",
      "2             1           cough  B-SYMPTOM\n",
      "3             1           after          O\n",
      "4             1  administration          O\n",
      "5             1              of          O\n",
      "6             1            75mg   B-DOSAGE\n",
      "7             1              of          O\n",
      "8             1           DrugZ          O\n",
      "9             2        Patients          O\n",
      "10            2     experienced          O\n",
      "11            2           fever  B-SYMPTOM\n",
      "12            2           after          O\n",
      "13            2          taking          O\n",
      "14            2            75mg   B-DOSAGE\n",
      "15            2              of          O\n",
      "16            2           DrugE          O\n",
      "17            3        Patients          O\n",
      "18            3     experienced          O\n",
      "19            3            rash  B-SYMPTOM\n"
     ]
    }
   ],
   "source": [
    "# 1. Combine words by sentence_id to form complete sentences\n",
    "sentences = ner_df.groupby('sentence_id')['word'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "sentences.columns = ['sentence_id', 'sentence']\n",
    "\n",
    "# 2. Remove duplicate sentences (keeping first occurrence)\n",
    "unique_sentences = sentences.drop_duplicates(subset='sentence', keep='first')\n",
    "\n",
    "# 3. Convert back to IOB format\n",
    "iob_data = []\n",
    "for _, row in unique_sentences.iterrows():\n",
    "    words = row['sentence'].split()\n",
    "    # Get the original tags for this sentence\n",
    "    original_tags = ner_df[ner_df['sentence_id'] == row['sentence_id']]['tag'].tolist()\n",
    "    \n",
    "    # Ensure we have tags for all words (in case some were lost in processing)\n",
    "    if len(original_tags) == len(words):\n",
    "        tags = original_tags\n",
    "    else:\n",
    "        # If tags don't match, default to 'O' (shouldn't happen with this approach)\n",
    "        tags = ['O'] * len(words)\n",
    "    \n",
    "    for word, tag in zip(words, tags):\n",
    "        iob_data.append({\n",
    "            'sentence_id': row['sentence_id'],\n",
    "            'word': word,\n",
    "            'tag': tag\n",
    "        })\n",
    "\n",
    "# Create new DataFrame\n",
    "deduplicated_df = pd.DataFrame(iob_data)\n",
    "\n",
    "# Save to CSV\n",
    "deduplicated_df.to_csv('deduplicated_medical_data.csv', index=False)\n",
    "\n",
    "print(\"Original number of sentences:\", ner_df['sentence_id'].nunique())\n",
    "print(\"Number of unique sentences:\", deduplicated_df['sentence_id'].nunique())\n",
    "print(\"\\nSample of cleaned data:\")\n",
    "print(deduplicated_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537a9a0",
   "metadata": {},
   "source": [
    "Notice that the `DrugZ` is tagged as O (outside, not important, not an entity to extract). Since we're training on this dataset, the model will learn that the drug names are NOT entities. \n",
    "\n",
    "However, \"the reasoning behind this is that we can obfuscate PII or PHI during training, but we should be able to replace the tag with the correct drug name during inference.\"\n",
    "\n",
    "I will still replace Drug[letter] with a random drug name to ensure that the model knows to recognize drugs. This keeps patient data protected since we are using random drugs anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae46a534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sentence_id       word     tag\n",
      "6076          849    Torisel  B-DRUG\n",
      "4241          547  Antivenin  B-DRUG\n",
      "5478          753  Entecavir  B-DRUG\n",
      "6218          876    Cubicin  B-DRUG\n",
      "2857          359     Extina  B-DRUG\n"
     ]
    }
   ],
   "source": [
    "url = \"https://gist.githubusercontent.com/ddbeck/56d54331a9c2526ff754/raw/fb8beb235bc97227a983a6d4e9a0067ecf9d29b5/drugs.json\"\n",
    "response = requests.get(url)\n",
    "drug_names = response.json()['drugs']\n",
    "\n",
    "# keep only drug names that are 1 words (avoid the complication of I-Drug data)\n",
    "clean_drugs = [d for d in drug_names if (' ' not in d) and ('-' not in d)]\n",
    "\n",
    "# Replace Drug[letter] with random real drugs\n",
    "drug_mask = deduplicated_df['word'].str.match(r'Drug[A-Z]$')  # Finds DrugA, DrugB, etc.\n",
    "\n",
    "# select rows where drug_mask is true in the column 'word', replaces drug placeholder with drug name in those cells\n",
    "deduplicated_df.loc[drug_mask, 'word'] = np.random.choice(clean_drugs, size=drug_mask.sum())\n",
    "\n",
    "# Update tags to B-DRUG\n",
    "deduplicated_df.loc[drug_mask, 'tag'] = 'B-DRUG'\n",
    "\n",
    "# Save corrected data\n",
    "deduplicated_df.to_csv(\"ner_data_drugged.csv\", index=False)\n",
    "print(deduplicated_df[deduplicated_df['tag'] == 'B-DRUG'].sample(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1b83a4",
   "metadata": {},
   "source": [
    "Make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15164ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample generated data:\n",
      "    sentence_id          word        tag\n",
      "0          1001     Following          O\n",
      "1          1001   consumption          O\n",
      "2          1001            of          O\n",
      "3          1001         750mg   B-DOSAGE\n",
      "4          1001    Streptase,     B-DRUG\n",
      "5          1001      Subjects          O\n",
      "6          1001   experienced          O\n",
      "7          1001       vertigo  B-SYMPTOM\n",
      "8          1002      Bleeding  B-SYMPTOM\n",
      "9          1002           was          O\n",
      "10         1002      reported          O\n",
      "11         1002            in          O\n",
      "12         1002  Participants          O\n",
      "13         1002          post          O\n",
      "14         1002       receipt          O\n",
      "15         1002            of          O\n",
      "16         1002         BiDil     B-DRUG\n",
      "17         1002        (80mg)   B-DOSAGE\n",
      "18         1003  Participants          O\n",
      "19         1003            on          O\n",
      "\n",
      "Unique tags in dataset: ['O' 'B-DOSAGE' 'B-DRUG' 'B-SYMPTOM']\n",
      "\n",
      "Sample drug names used: ['Acthrel', 'Riomet', 'Atropen', 'Artane', 'Thiethylperazine', 'Uvadex', 'Aphthasol', 'Saizen', 'Zafirlukast', 'Provera']\n"
     ]
    }
   ],
   "source": [
    "# Fetch real drug names from the provided URL\n",
    "url = \"https://gist.githubusercontent.com/ddbeck/56d54331a9c2526ff754/raw/fb8beb235bc97227a983a6d4e9a0067ecf9d29b5/drugs.json\"\n",
    "response = requests.get(url)\n",
    "drug_names = response.json()['drugs']\n",
    "# keep only drug names that are 1 words (avoid the complication of I-Drug data)\n",
    "clean_drugs = [d for d in drug_names if (' ' not in d) and ('-' not in d)]\n",
    "drug_names = clean_drugs\n",
    "\n",
    "# Define other components with medical variations\n",
    "subjects = [\"Patients\", \"Subjects\", \"Individuals\", \"Participants\", \"Volunteers\", \"Cases\", \"Users\"]\n",
    "verbs = [\"experienced\", \"reported\", \"developed\", \"presented with\", \"exhibited\", \"showed\", \"complained of\"]\n",
    "symptoms = [\n",
    "    \"diarrhea\", \"constipation\", \"sweating\", \"itching\", \"swelling\", \n",
    "    \"weakness\", \"tremors\", \"cramps\", \"bruising\", \"bleeding\",\n",
    "    \"palpitations\", \"confusion\", \"insomnia\", \"anxiety\", \"depression\",\n",
    "    \"bloating\", \"gas\", \"dehydration\", \"syncope\", \"vertigo\"\n",
    "]\n",
    "prepositions = [\"after\", \"following\", \"within hours of\", \"within days of\", \"post\", \"subsequent to\"]\n",
    "actions = [\"administration\", \"ingestion\", \"consumption\", \"receipt\", \"intake\", \"dosage\", \"treatment with\"]\n",
    "dosages = [\n",
    "    \"20mg\", \"40mg\", \"80mg\", \"120mg\", \"150mg\", \"300mg\", \"400mg\", \n",
    "    \"600mg\", \"750mg\", \"1g\", \"2.5mg\", \"12.5mg\", \"15mg\", \"30mg\", \n",
    "    \"45mg\", \"60mg\", \"0.5mg\", \"0.25mg\", \"5ml\", \"10ml\"\n",
    "]\n",
    "timeframes = [\"1 hour\", \"2 days\", \"24 hours\", \"3 weeks\", \"several minutes\", \"a few days\", \"48 hours\", \"5 days\"]\n",
    "\n",
    "# More diverse sentence structures\n",
    "structures = [\n",
    "    lambda: f\"{random.choice(subjects)} {random.choice(verbs)} {random.choice(symptoms)} {random.choice(prepositions)} {random.choice(actions)} of {random.choice(dosages)} of {random.choice(clean_drugs)}\",\n",
    "    lambda: f\"{random.choice(subjects)} {random.choice(verbs)} {random.choice(symptoms)} {random.choice(prepositions)} taking {random.choice(dosages)} of {random.choice(clean_drugs)}\",\n",
    "    lambda: f\"Following {random.choice(actions)} of {random.choice(dosages)} {random.choice(clean_drugs)}, {random.choice(subjects)} {random.choice(verbs)} {random.choice(symptoms)}\",\n",
    "    lambda: f\"{random.choice(symptoms).capitalize()} was {random.choice(['observed', 'reported'])} in {random.choice(subjects)} {random.choice(prepositions)} {random.choice(actions)} of {random.choice(clean_drugs)} ({random.choice(dosages)})\",\n",
    "    lambda: f\"{random.choice(subjects)} on {random.choice(dosages)} {random.choice(clean_drugs)} {random.choice(verbs)} {random.choice(symptoms)} within {random.choice(timeframes)}\",\n",
    "    lambda: f\"{random.choice(clean_drugs)} at {random.choice(dosages)} {random.choice(['caused', 'induced', 'led to'])} {random.choice(symptoms)} in {random.choice(subjects)}\",\n",
    "    lambda: f\"{random.choice(subjects)} {random.choice(['started', 'began'])} {random.choice(verbs)} {random.choice(symptoms)} {random.choice(prepositions)} {random.choice(clean_drugs)} therapy ({random.choice(dosages)})\",\n",
    "    lambda: f\"{random.choice(['The', 'A'])} {random.choice(symptoms)} {random.choice(['occurred', 'appeared'])} {random.choice(prepositions)} {random.choice(clean_drugs)} use ({random.choice(dosages)})\"\n",
    "]\n",
    "\n",
    "def clean_word(word):\n",
    "    \"\"\"Remove surrounding punctuation from a word\"\"\"\n",
    "    return re.sub(r'^[^a-zA-Z0-9]*|[^a-zA-Z0-9]*$', '', word)\n",
    "\n",
    "def generate_sentence():\n",
    "    sentence = random.choice(structures)()\n",
    "    # Clean up punctuation and spacing\n",
    "    sentence = re.sub(r'\\s([?.!,\"](?:\\s|$))', r'\\1', sentence)\n",
    "    return sentence\n",
    "\n",
    "def tag_sentence(sentence):\n",
    "    words = sentence.split()\n",
    "    tags = ['O'] * len(words)\n",
    "    \n",
    "    # Find and tag symptoms (only B- tag as we're not using I- tags)\n",
    "    for i, word in enumerate(words):\n",
    "        lower_word = clean_word(word).lower()\n",
    "        if lower_word in [s.lower() for s in symptoms]:\n",
    "            tags[i] = 'B-SYMPTOM'\n",
    "    \n",
    "    # Find and tag dosages (pattern: number + mg, even with punctuation)\n",
    "    for i, word in enumerate(words):\n",
    "        clean_w = clean_word(word)\n",
    "        # Matches: 45mg, (45mg), 1g, (1g), etc.\n",
    "        if re.match(r'^\\(?\\d+\\.?\\d*[a-zA-Z]+\\)?$', clean_w.lower()):\n",
    "            tags[i] = 'B-DOSAGE'\n",
    "    \n",
    "    # Find and tag drugs (case-sensitive match with cleaned word)\n",
    "    for i, word in enumerate(words):\n",
    "        clean_w = clean_word(word)\n",
    "        if clean_w in clean_drugs:\n",
    "            tags[i] = 'B-DRUG'\n",
    "    \n",
    "    return words, tags\n",
    "\n",
    "def generate_data(num_sentences, start_id=1):\n",
    "    data = []\n",
    "    sentence_id = start_id\n",
    "    \n",
    "    for _ in range(num_sentences):\n",
    "        sentence = generate_sentence()\n",
    "        words, tags = tag_sentence(sentence)\n",
    "        \n",
    "        for word, tag in zip(words, tags):\n",
    "            data.append({\n",
    "                'sentence_id': sentence_id,\n",
    "                'word': word,\n",
    "                'tag': tag\n",
    "            })\n",
    "        \n",
    "        sentence_id += 1\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate 200 sentences for better variety\n",
    "df = generate_data(500, start_id=1001)\n",
    "\n",
    "# Verify we only have the specified tags\n",
    "assert set(df['tag'].unique()) == {'O', 'B-SYMPTOM', 'B-DOSAGE', 'B-DRUG'}, \"Invalid tags detected\"\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('synthetic_medical_ner_data_iob.csv', index=False)\n",
    "\n",
    "print(\"Sample generated data:\")\n",
    "print(df.head(20))\n",
    "print(\"\\nUnique tags in dataset:\", df['tag'].unique())\n",
    "print(\"\\nSample drug names used:\", random.sample(drug_names, 10))\n",
    "\n",
    "# Append to your existing data\n",
    "combined_df = pd.concat([deduplicated_df, df], ignore_index=True)\n",
    "combined_df.to_csv('deduplicated_suppl_ner_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0033a3b7",
   "metadata": {},
   "source": [
    "Now that the data is different enough, we can begin work on the NER model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a99984",
   "metadata": {},
   "source": [
    "# DEEPSEEK GENERATED CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "407b9c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 Label Distribution:\n",
      "  O: 7545\n",
      "  B-SYMPTOM: 1325\n",
      "  B-DOSAGE: 1325\n",
      "  B-DRUG: 1325\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def load_conll_data(file_path):\n",
    "    \"\"\"Load CoNLL format data and convert to sentences with labels\"\"\"\n",
    "    # Read the data\n",
    "    ner_df = pd.read_csv(file_path)\n",
    "\n",
    "    # Group by sentence_id to reconstruct sentences\n",
    "    sentences = []\n",
    "    labels = []\n",
    "\n",
    "    for sentence_id in ner_df['sentence_id'].unique():\n",
    "        sentence_data = ner_df[ner_df['sentence_id'] == sentence_id]\n",
    "        sentence_words = sentence_data['word'].tolist()\n",
    "        sentence_tags = sentence_data['tag'].tolist()\n",
    "\n",
    "        sentences.append(sentence_words)\n",
    "        labels.append(sentence_tags)\n",
    "\n",
    "    return sentences, labels\n",
    "\n",
    "\n",
    "sentences, labels = load_conll_data(\"deduplicated_suppl_ner_data.csv\")\n",
    "\n",
    "# 3. Analyze Label Distribution\n",
    "def analyze_labels(labels):\n",
    "    \"\"\"Analyze the distribution of entity labels\"\"\"\n",
    "    all_labels = [label for sentence_labels in labels for label in sentence_labels]\n",
    "    label_counts = pd.Series(all_labels).value_counts()\n",
    "\n",
    "    print(\"\\n📈 Label Distribution:\")\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"  {label}: {count}\")\n",
    "\n",
    "    return label_counts\n",
    "\n",
    "label_counts = analyze_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ba89322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏷️  Found 4 unique labels:\n",
      "  B-DOSAGE: 0\n",
      "  B-DRUG: 1\n",
      "  B-SYMPTOM: 2\n",
      "  O: 3\n"
     ]
    }
   ],
   "source": [
    "# 4. Create Label Mappings\n",
    "def create_label_mappings(labels):\n",
    "    \"\"\"Create mappings between labels and ids\"\"\"\n",
    "    unique_labels = set(label for sentence_labels in labels for label in sentence_labels)\n",
    "    label_to_id = {label: i for i, label in enumerate(sorted(unique_labels))}\n",
    "    id_to_label = {i: label for label, i in label_to_id.items()}\n",
    "\n",
    "    print(f\"\\n🏷️  Found {len(unique_labels)} unique labels:\")\n",
    "    for label, id in sorted(label_to_id.items()):\n",
    "        print(f\"  {label}: {id}\")\n",
    "\n",
    "    return label_to_id, id_to_label\n",
    "\n",
    "label_to_id, id_to_label = create_label_mappings(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a505925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔤 Initializing tokenizer...\n",
      "✂️  Splitting data...\n",
      "🚂 Training sentences: 1060\n",
      "🔍 Validation sentences: 265\n",
      "🔤 Tokenizing and aligning labels...\n",
      "🤖 Initializing DistilBERT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👨‍🏫 Initializing trainer...\n"
     ]
    }
   ],
   "source": [
    "# 5. Tokenization and Alignment\n",
    "def tokenize_and_align_labels(sentences, labels, tokenizer, label_to_id):\n",
    "    \"\"\"Tokenize sentences and align labels with subword tokens\"\"\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        sentences,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        is_split_into_words=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    aligned_labels = []\n",
    "\n",
    "    for i, sentence_labels in enumerate(labels):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                # Special tokens get -100 label (ignored in loss)\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # First token of a word gets the actual label\n",
    "                label_ids.append(label_to_id[sentence_labels[word_idx]])\n",
    "            else:\n",
    "                # Subsequent tokens of the same word get -100 (ignored)\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        aligned_labels.append(label_ids)\n",
    "\n",
    "    return tokenized_inputs, aligned_labels\n",
    "\n",
    "# Initialize tokenizer\n",
    "print(\"\\n🔤 Initializing tokenizer...\")\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# 6. Train-Test Split\n",
    "print(\"✂️  Splitting data...\")\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    sentences, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"🚂 Training sentences: {len(train_sentences)}\")\n",
    "print(f\"🔍 Validation sentences: {len(val_sentences)}\")\n",
    "\n",
    "\n",
    "# 7. Tokenize and align labels\n",
    "print(\"🔤 Tokenizing and aligning labels...\")\n",
    "train_tokenized, train_aligned_labels = tokenize_and_align_labels(\n",
    "    train_sentences, train_labels, tokenizer, label_to_id\n",
    ")\n",
    "val_tokenized, val_aligned_labels = tokenize_and_align_labels(\n",
    "    val_sentences, val_labels, tokenizer, label_to_id\n",
    ")\n",
    "\n",
    "\n",
    "# 8. Create Dataset Class\n",
    "class NERDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = NERDataset(train_tokenized, train_aligned_labels)\n",
    "val_dataset = NERDataset(val_tokenized, val_aligned_labels)\n",
    "\n",
    "# 9. Initialize Model\n",
    "print(\"🤖 Initializing DistilBERT model...\")\n",
    "model = DistilBertForTokenClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=len(label_to_id),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")\n",
    "\n",
    "# 10. Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/ner_results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"/tmp/ner_logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    ")\n",
    "\n",
    "# 11. Data Collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "# 12. Custom Metrics Function\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute entity-level precision, recall, and F1 score\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [id_to_label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id_to_label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    # Flatten for sklearn metrics\n",
    "    flat_true_labels = [label for sentence in true_labels for label in sentence]\n",
    "    flat_predictions = [pred for sentence in true_predictions for pred in sentence]\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        flat_true_labels, flat_predictions, average='weighted', zero_division=0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n",
    "# 13. Initialize Trainer\n",
    "print(\"👨‍🏫 Initializing trainer...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmichellew\u001b[0m (\u001b[33mmichellew-mcmaster-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\Libraries\\OneDrive - McMaster University\\McMaster Docs (MAC)\\Work\\FT Job\\Aten Security\\wandb\\run-20250619_210651-dntlf55z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/michellew-mcmaster-university/huggingface/runs/dntlf55z' target=\"_blank\">/tmp/ner_results</a></strong> to <a href='https://wandb.ai/michellew-mcmaster-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/michellew-mcmaster-university/huggingface' target=\"_blank\">https://wandb.ai/michellew-mcmaster-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/michellew-mcmaster-university/huggingface/runs/dntlf55z' target=\"_blank\">https://wandb.ai/michellew-mcmaster-university/huggingface/runs/dntlf55z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='201' max='201' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [201/201 01:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.999569</td>\n",
       "      <td>0.999568</td>\n",
       "      <td>0.999568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.999569</td>\n",
       "      <td>0.999568</td>\n",
       "      <td>0.999568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.999569</td>\n",
       "      <td>0.999568</td>\n",
       "      <td>0.999568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Final Evaluation:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  eval_loss: 0.0023\n",
      "  eval_precision: 0.9996\n",
      "  eval_recall: 0.9996\n",
      "  eval_f1: 0.9996\n",
      "  eval_runtime: 1.2744\n",
      "  eval_samples_per_second: 207.9340\n",
      "  eval_steps_per_second: 13.3390\n",
      "  epoch: 3.0000\n"
     ]
    }
   ],
   "source": [
    "# 14. Train the Model\n",
    "print(\"🚀 Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# 15. Final Evaluation\n",
    "print(\"\\n📊 Final Evaluation:\")\n",
    "final_metrics = trainer.evaluate()\n",
    "for key, value in final_metrics.items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c486ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Entity-Level Evaluation Function\n",
    "def evaluate_entities(sentences, true_labels, predictions, id_to_label):\n",
    "    \"\"\"Extract and evaluate entities at the entity level\"\"\"\n",
    "    def extract_entities(tokens, labels):\n",
    "        entities = []\n",
    "        current_entity = []\n",
    "        current_label = None\n",
    "\n",
    "        for token, label in zip(tokens, labels):\n",
    "            if label.startswith('B-'):  # Beginning of entity\n",
    "                if current_entity:  # Save previous entity\n",
    "                    entities.append((' '.join(current_entity), current_label))\n",
    "                current_entity = [token]\n",
    "                current_label = label[2:]  # Remove B- prefix\n",
    "            elif label.startswith('I-') and current_label == label[2:]:  # Inside entity\n",
    "                current_entity.append(token)\n",
    "            else:  # Outside entity or different entity\n",
    "                if current_entity:\n",
    "                    entities.append((' '.join(current_entity), current_label))\n",
    "                current_entity = []\n",
    "                current_label = None\n",
    "\n",
    "        if current_entity:  # Don't forget the last entity\n",
    "            entities.append((' '.join(current_entity), current_label))\n",
    "\n",
    "        return entities\n",
    "\n",
    "    true_entities = []\n",
    "    pred_entities = []\n",
    "\n",
    "    for sent_tokens, sent_true, sent_pred in zip(sentences, true_labels, predictions):\n",
    "        # Convert predictions back to labels\n",
    "        sent_pred_labels = [id_to_label[p] for p in sent_pred if p != -100]\n",
    "        sent_true_labels = [l for l in sent_true if l != 'O']  # Filter out O labels for entity extraction\n",
    "\n",
    "        true_ents = extract_entities(sent_tokens, sent_true)\n",
    "        pred_ents = extract_entities(sent_tokens, sent_pred_labels)\n",
    "\n",
    "        true_entities.extend(true_ents)\n",
    "        pred_entities.extend(pred_ents)\n",
    "\n",
    "    return true_entities, pred_entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61765901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Prediction Function\n",
    "# Outputs just extracted entities\n",
    "def predict_entities(text, model, tokenizer, label_to_id, id_to_label):\n",
    "    \"\"\"Predict entities in a given text\"\"\"\n",
    "    # Tokenize the input\n",
    "    tokens = text.split()\n",
    "    inputs = tokenizer(tokens, is_split_into_words=True, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "    # Get predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=2)\n",
    "\n",
    "    # Align predictions with original tokens\n",
    "    word_ids = inputs.word_ids()\n",
    "    aligned_predictions = []\n",
    "\n",
    "    previous_word_idx = None\n",
    "    for word_idx, pred_id in zip(word_ids, predictions[0]):\n",
    "        if word_idx is not None and word_idx != previous_word_idx:\n",
    "            aligned_predictions.append(id_to_label[pred_id.item()])\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    # Extract entities\n",
    "    entities = []\n",
    "    current_entity = []\n",
    "    current_label = None\n",
    "\n",
    "    for token, label in zip(tokens, aligned_predictions):\n",
    "        if label.startswith('B-'):\n",
    "            if current_entity:\n",
    "                entities.append({\n",
    "                    'text': ' '.join(current_entity),\n",
    "                    'label': current_label,\n",
    "                    'start': tokens.index(current_entity[0]),\n",
    "                    'end': tokens.index(current_entity[-1]) + 1\n",
    "                })\n",
    "            current_entity = [token]\n",
    "            current_label = label[2:]\n",
    "        elif label.startswith('I-') and current_label == label[2:]:\n",
    "            current_entity.append(token)\n",
    "        else:\n",
    "            if current_entity:\n",
    "                entities.append({\n",
    "                    'text': ' '.join(current_entity),\n",
    "                    'label': current_label,\n",
    "                    'start': tokens.index(current_entity[0]),\n",
    "                    'end': tokens.index(current_entity[-1]) + 1\n",
    "                })\n",
    "            current_entity = []\n",
    "            current_label = None\n",
    "\n",
    "    if current_entity:\n",
    "        entities.append({\n",
    "            'text': ' '.join(current_entity),\n",
    "            'label': current_label,\n",
    "            'start': tokens.index(current_entity[0]),\n",
    "            'end': tokens.index(current_entity[-1]) + 1\n",
    "        })\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d51f866b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Testing with example sentence:\n",
      "Input: Patients were given 50mg of Aspirin and developed rash\n",
      "Predicted Entities:\n",
      "  - DOSAGE: 50mg\n",
      "  - DRUG: Aspirin\n",
      "  - SYMPTOM: rash\n"
     ]
    }
   ],
   "source": [
    "# 18. Test the Model with Example\n",
    "print(\"\\n🧪 Testing with example sentence:\")\n",
    "example_text = \"Patients were given 50mg of Aspirin and developed rash\"\n",
    "predicted_entities = predict_entities(example_text, model, tokenizer, label_to_id, id_to_label)\n",
    "\n",
    "print(f\"Input: {example_text}\")\n",
    "print(\"Predicted Entities:\")\n",
    "for entity in predicted_entities:\n",
    "    print(f\"  - {entity['label']}: {entity['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a7c7b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 Detailed Entity-Level Evaluation:\n",
      "\n",
      "Entity-Level Metrics by Type:\n",
      "  DRUG:\n",
      "    Precision: 0.9962\n",
      "    Recall: 1.0000\n",
      "    F1-Score: 0.9981\n",
      "    True entities: 265\n",
      "    Predicted entities: 266\n",
      "  SYMPTOM:\n",
      "    Precision: 1.0000\n",
      "    Recall: 1.0000\n",
      "    F1-Score: 1.0000\n",
      "    True entities: 265\n",
      "    Predicted entities: 265\n",
      "  DOSAGE:\n",
      "    Precision: 1.0000\n",
      "    Recall: 1.0000\n",
      "    F1-Score: 1.0000\n",
      "    True entities: 265\n",
      "    Predicted entities: 265\n",
      "\n",
      "✅ NER Model Training Complete!\n",
      "🎯 Model successfully trained to extract Drug Names, Symptoms, and Dosages\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 19. Detailed Entity-Level Evaluation\n",
    "print(\"\\n📈 Detailed Entity-Level Evaluation:\")\n",
    "\n",
    "# Get predictions for validation set\n",
    "val_predictions = trainer.predict(val_dataset)\n",
    "val_pred_labels = np.argmax(val_predictions.predictions, axis=2)\n",
    "\n",
    "# Filter out -100 labels and convert to entity format\n",
    "filtered_predictions = []\n",
    "filtered_true_labels = []\n",
    "\n",
    "for i, (pred_seq, true_seq) in enumerate(zip(val_pred_labels, val_aligned_labels)):\n",
    "    pred_filtered = [id_to_label[p] for p, t in zip(pred_seq, true_seq) if t != -100]\n",
    "    true_filtered = [id_to_label[t] for t in true_seq if t != -100]\n",
    "\n",
    "    filtered_predictions.append(pred_filtered)\n",
    "    filtered_true_labels.append(true_filtered)\n",
    "\n",
    "# Calculate entity-level metrics by entity type\n",
    "entity_types = ['DRUG', 'SYMPTOM', 'DOSAGE']\n",
    "print(\"\\nEntity-Level Metrics by Type:\")\n",
    "\n",
    "for entity_type in entity_types:\n",
    "    true_entities = []\n",
    "    pred_entities = []\n",
    "\n",
    "    for sent_idx, (sent_tokens, true_labels, pred_labels) in enumerate(\n",
    "        zip(val_sentences, val_labels, filtered_predictions)\n",
    "    ):\n",
    "        # Extract entities of this type\n",
    "        def extract_entities_of_type(tokens, labels, target_type):\n",
    "            entities = []\n",
    "            current_entity = []\n",
    "\n",
    "            for token, label in zip(tokens, labels):\n",
    "                if label == f'B-{target_type}':\n",
    "                    if current_entity:\n",
    "                        entities.append(' '.join(current_entity))\n",
    "                    current_entity = [token]\n",
    "                elif label == f'I-{target_type}' and current_entity:\n",
    "                    current_entity.append(token)\n",
    "                else:\n",
    "                    if current_entity:\n",
    "                        entities.append(' '.join(current_entity))\n",
    "                        current_entity = []\n",
    "\n",
    "            if current_entity:\n",
    "                entities.append(' '.join(current_entity))\n",
    "\n",
    "            return entities\n",
    "\n",
    "        true_ents = extract_entities_of_type(sent_tokens, true_labels, entity_type)\n",
    "        pred_ents = extract_entities_of_type(sent_tokens, pred_labels, entity_type)\n",
    "\n",
    "        true_entities.extend([(ent, sent_idx) for ent in true_ents])\n",
    "        pred_entities.extend([(ent, sent_idx) for ent in pred_ents])\n",
    "\n",
    "    # Calculate precision, recall, F1\n",
    "    true_set = set(true_entities)\n",
    "    pred_set = set(pred_entities)\n",
    "\n",
    "    if len(pred_set) > 0:\n",
    "        precision = len(true_set & pred_set) / len(pred_set)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "\n",
    "    if len(true_set) > 0:\n",
    "        recall = len(true_set & pred_set) / len(true_set)\n",
    "    else:\n",
    "        recall = 0.0\n",
    "\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0.0\n",
    "\n",
    "    print(f\"  {entity_type}:\")\n",
    "    print(f\"    Precision: {precision:.4f}\")\n",
    "    print(f\"    Recall: {recall:.4f}\")\n",
    "    print(f\"    F1-Score: {f1:.4f}\")\n",
    "    print(f\"    True entities: {len(true_set)}\")\n",
    "    print(f\"    Predicted entities: {len(pred_set)}\")\n",
    "\n",
    "print(\"\\n✅ NER Model Training Complete!\")\n",
    "print(\"🎯 Model successfully trained to extract Drug Names, Symptoms, and Dosages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc22de91",
   "metadata": {},
   "source": [
    "Example Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e11272ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Input Text: 500mg Tylenol every 6h for fever, but dizziness occurred\n",
      "\n",
      "Predicted Entities:\n",
      "- DOSAGE: '500mg' (positions 0-1)\n",
      "- DRUG: 'Tylenol' (positions 1-2)\n",
      "- DOSAGE: '6h' (positions 3-4)\n",
      "- SYMPTOM: 'fever,' (positions 5-6)\n",
      "- SYMPTOM: 'dizziness' (positions 7-8)\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Input Text: Patients experienced cough after administration of 75mg of Multaq\n",
      "\n",
      "Predicted Entities:\n",
      "- SYMPTOM: 'cough' (positions 2-3)\n",
      "- DOSAGE: '75mg' (positions 6-7)\n",
      "- DRUG: 'Multaq' (positions 8-9)\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Input Text: Aspirin 81mg daily caused GI bleeding and tinnitus\n",
      "\n",
      "Predicted Entities:\n",
      "- DRUG: 'Aspirin' (positions 0-1)\n",
      "- DOSAGE: '81mg' (positions 1-2)\n",
      "- SYMPTOM: 'GI' (positions 4-5)\n",
      "- SYMPTOM: 'bleeding' (positions 5-6)\n",
      "- DRUG: 'tinnitus' (positions 7-8)\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Input Text: Overdose on CaCO3 (calcium carbonate): vomiting, drowsiness\n",
      "\n",
      "Predicted Entities:\n",
      "- DRUG: 'CaCO3' (positions 2-3)\n",
      "- DRUG: 'carbonate):' (positions 4-5)\n",
      "- SYMPTOM: 'vomiting,' (positions 5-6)\n",
      "- SYMPTOM: 'drowsiness' (positions 6-7)\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Input Text: Lisinoprol 10mg led to dry cough and fatigue\n",
      "\n",
      "Predicted Entities:\n",
      "- DRUG: 'Lisinoprol' (positions 0-1)\n",
      "- DOSAGE: '10mg' (positions 1-2)\n",
      "- SYMPTOM: 'dry' (positions 4-5)\n",
      "- SYMPTOM: 'cough' (positions 5-6)\n",
      "- SYMPTOM: 'fatigue' (positions 7-8)\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Input Text: Janumet XR 50mg/1000mg BID caused diarrhea\n",
      "\n",
      "Predicted Entities:\n",
      "- DRUG: 'Janumet' (positions 0-1)\n",
      "- DRUG: 'XR' (positions 1-2)\n",
      "- DOSAGE: '50mg/1000mg' (positions 2-3)\n",
      "- DRUG: 'BID' (positions 3-4)\n",
      "- SYMPTOM: 'diarrhea' (positions 5-6)\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Input Text: Street drug 'Molly' induced hyperthermia and seizures\n",
      "\n",
      "Predicted Entities:\n",
      "- SYMPTOM: 'hyperthermia' (positions 4-5)\n",
      "- SYMPTOM: 'seizures' (positions 6-7)\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Input Text: No ibuprofen use, but naproxen 250mg caused dyspepsia\n",
      "\n",
      "Predicted Entities:\n",
      "- DRUG: 'ibuprofen' (positions 1-2)\n",
      "- DRUG: 'naproxen' (positions 4-5)\n",
      "- DOSAGE: '250mg' (positions 5-6)\n",
      "- SYMPTOM: 'dyspepsia' (positions 7-8)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"text\": \"500mg Tylenol every 6h for fever, but dizziness occurred\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Patients experienced cough after administration of 75mg of Multaq\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Aspirin 81mg daily caused GI bleeding and tinnitus\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Overdose on CaCO3 (calcium carbonate): vomiting, drowsiness\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Lisinoprol 10mg led to dry cough and fatigue\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Janumet XR 50mg/1000mg BID caused diarrhea\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Street drug 'Molly' induced hyperthermia and seizures\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"No ibuprofen use, but naproxen 250mg caused dyspepsia\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for example in examples:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Input Text: {example['text']}\")\n",
    "    \n",
    "    # Get predictions\n",
    "    predicted_entities = predict_entities(\n",
    "        text=example[\"text\"],\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        label_to_id=label_to_id,  # Ensure this is defined\n",
    "        id_to_label=id_to_label   # Ensure this is defined\n",
    "    )\n",
    "    \n",
    "    # Print predicted entities\n",
    "    print(\"\\nPredicted Entities:\")\n",
    "    for ent in predicted_entities:\n",
    "        print(f\"- {ent['label']}: '{ent['text']}' (positions {ent['start']}-{ent['end']})\")\n",
    "    \n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b195ce02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('clinical_ner_model_v2\\\\tokenizer_config.json',\n",
       " 'clinical_ner_model_v2\\\\special_tokens_map.json',\n",
       " 'clinical_ner_model_v2\\\\vocab.txt',\n",
       " 'clinical_ner_model_v2\\\\added_tokens.json',\n",
       " 'clinical_ner_model_v2\\\\tokenizer.json')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"clinical_ner_model_v2\")\n",
    "tokenizer.save_pretrained(\"clinical_ner_model_v2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
